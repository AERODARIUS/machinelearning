{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Entrega 2 - Arboles de decisión\n",
    "\n",
    "### Grupo 6:\n",
    "     - Darío Cruz  4768599-2\n",
    "     - Agustin Tornaría 5047825-5\n",
    "     - Renzo Beux 5076905-8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Objetivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "El objetivo de esta tarea es implementar el algoritmo ID3 para utilizarlo con el conjunto de datos de Heart Disease UCI.\n",
    "\n",
    "Se compararan los resultados obtenidos con los de la implementación de Decision Tree de scikit-learn."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Diseño"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Preprocesamiento de datos\n",
    "<!-- - Decisiones sobre tratamiento de datos numéricos, faltantes, etc. antes de la aplicación de el algoritmo\n",
    "- Selección/generación de atributos -->\n",
    "\n",
    "Los datos son presentado en una planilla separada por comas (CSV) la cual es consumida utilizando Pandas. No se realiza ningun filtrado ni corrección sobre los datos. Simplemente se parte los datos en dos conjuntos, uno para relizar el entrenamiento y otro para realizar las pruebas.\n",
    "La selección de atributos esta dada por el algoritmo mismo la cual será explicada a continuación.\n",
    "\n",
    "\n",
    "## 2.2 Algoritmo\n",
    "<!-- Extensiones del algoritmo original necesarias para la resolución del problema: tratamiento de atributos faltantes, numéricos, etc. (si es el propio algoritmo el que lo maneja), implementaciones adicionales necesarias para manejar ensambles de clasificadores, etc. -->\n",
    "\n",
    "Se utilizó el algoritmo ID3 para la generacion del arbol. Se programó el algoritmo visto en clase y presentado en el libro del curso. Para cada atributo se calcula la ganancia de todas las particiones en dos. Para ello se ordenan y agrupan los valores de la columna correspondiente al atributo elegido, calculando para cada partición la ganancia de la misma. Esta ganancia es calculada a apartir de la entropía de ambas partes de la particion.\n",
    "\n",
    "Teniendo entonces todas las ganancias de todos los atributos para todas la particiones, nos quedamos con el atributo y la partición que tengan la mayor ganancia. \n",
    "\n",
    "Habiendo obtenido esto quitamos la columna con la propiedad anteriormente elegida del dataset y se la pasamos a los siguientes nodos del arbol, guardando en el nodo actual el atributo y el umbral por el cual se particiona en dos. Teniendo en cuenta que las particiones fueron ordenadas, el umbral es el punto medio entre el mayor de los valores del primer conjunto de la partición y el menor valor de la segundo conjunto de la partición. A la izquierda se encuentran los nodos que son menores o iguales al umbral y a la derecha los que son mayores al umbral. De esta manera el árbol de decisión se va armando recursivamente.\n",
    "\n",
    "\n",
    "## 2.3 Evaluación\n",
    "<!-- - Qué conjunto de métricas se utilizan para la evaluación de la solución y su definición\n",
    "- Sobre qué conjunto(s) se realiza el entrenamiento, ajuste de la solución, evaluación, etc. Explicar cómo se construyen estos conjuntos. -->\n",
    "\n",
    "Para la evaluacion de nuestro algoritmo se utiliza la libreria scikit-learn de Python. Utilizando la utilidad \"tree\" junto con la implementacion \"DecisionTreeClassifier(criterion=\"entropy\")\", en donde es importante notar que se setea el criterio como \"entropy\" ya que por defecto SciKit selecciona Gini.\n",
    "\n",
    "Se entrena con un porcentaje de los datos y se utilizan el resto de los datos para probar el arbol de decisión. Se compararon con los porcentajes obtenidos con SciKit.\n",
    "\n",
    "En un principio se entrenó con 80% de los datos, luego se experimientó con otros porcentajes.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Experimentación"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los experimentos que se realizaron se basan en elegir un porcentaje de los datos para entrenar el algoritmo y el restante de los datos para probar las predicciones. Los porcentajes con los que probamos fueron los siguientes:\n",
    "\n",
    "| Entrenamiento | Test | Presición |\n",
    "|---------------|------|-----------|\n",
    "| 9%            | 91%  | 59.0%     |\n",
    "| 19%           | 81%  | 72.7%     |\n",
    "| 29%           | 71%  | 70.8%     |\n",
    "| 39%           | 61%  | 75.6%     |\n",
    "| 49%           | 51%  | 77.4%     |\n",
    "| 59%           | 41%  | 76.8%     |\n",
    "| 69%           | 31%  | 73.4%     |\n",
    "| 79%           | 21%  | 81.2%     |\n",
    "| 89%           | 11%  | 76.4%     |\n",
    "| 99%           |  1%  | 75.0%     |\n",
    "\n",
    "Luego graficamos los resultados.\n",
    "\n",
    "![Aciertos por experimento - algoritmo](grafica_nuestroID3.png)\n",
    "\n",
    "_En la gráfica se puede ver el porcentaje de aciertos en función del porcentaje de entrenamiento para nuestro algoritmo_\n",
    "\n",
    "# Repetimos lo mismo con el algoritmo de scikit-learn\n",
    "\n",
    "| Entrenamiento | Test | Presición |\n",
    "|---------------|------|-----------|\n",
    "| 9%            | 91%  | 53.6%     |\n",
    "| 19%           | 81%  | 75.6%     |\n",
    "| 29%           | 71%  | 73.6%     |\n",
    "| 39%           | 61%  | 72.4%     |\n",
    "| 49%           | 51%  | 76.7%     |\n",
    "| 59%           | 41%  | 79.2%     |\n",
    "| 69%           | 31%  | 74.4%     |\n",
    "| 79%           | 21%  | 75.0%     |\n",
    "| 89%           | 11%  | 82.3%     |\n",
    "| 99%           |  1%  | 75.0%     |\n",
    "\n",
    "![Aciertos por experimento - scikit-learn](grafica_scikit.png)\n",
    "_En la gráfica se puede ver el porcentaje de aciertos en función del porcentaje de entrenamiento para SciKit_\n",
    "\n",
    "\n",
    "Se puede ver en ambas gráficas que a medida que fuimos utilizando un mayor porcentaje de datos para entrenamiento, el algoritmo fue mejorando la precisión. Pero al utilizar un conjunto demasiado grande de datos para entrenamiento, el algoritmo queda demasiado específico para esos datos, y por lo tanto decrece el porcentaje de aciertos.\n",
    "\n",
    "El algoritmo de scikit-learn tuvo una precisión bastante parecida a la de nuestro algoritmo.\n",
    "\n",
    "Algo que notamos es que nos parece importante al momento de comparar algoritmos es que nuestro algoritmo es relativamente mas lento que Scikit-Learn. Sin embargo creemos que esto se da por varios motivos, pero el que suponemos más probable es por el uso de estructuras optimizadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Conclusión"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se puede observar que al empezar a utilizar más datos de entrenamiento mejoran los resultados, pero si se aumentan mucho el arbol se vuelve demasiado específico y esto hace que empeoren los resultados. Por esto el mejor resultado se da en un entorno cercano a 80% donde se tienen suficientes datos para obtener un buen resultado pero no tantos como para empeorarlo.\r\n",
    "Una forma de mejorar el problema de hacerlo demasiado específico es utilizar la técnica de poda. Donde se convierten algunas ramas en hojas.\r\n",
    "Otro punto de mejora puede ser utilizar el indice de Gini en lugar de la entropía.\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}