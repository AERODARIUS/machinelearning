{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 3 - Clasificador con Aprendizaje Bayesiano y KNN\n",
    "\n",
    "### Grupo 6:\n",
    "     - Renzo Beux 5076905-8\n",
    "     - Darío Cruz  4768599-2\n",
    "     - Agustín Tornaría 5047825-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta tarea es construir un clasificador no supervisado, utilizando el metodo de clusteres k-means y reduciendo las dimensiones del problema utilizando PCA. \n",
    "\n",
    "Se probarán distintos hiperparámetros y se analizarán los resultados, en particular comparándolos con las regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocesamiento de datos\n",
    "Los datos son presentados en una planilla CSV que se consume utilizando Pandas, y luego le extraemos las columnas de datos no continuos: \"Country\" y \"Region\". Los atributos restantes son todos numéricos, pero algunos están almacenados en el csv como texto, por lo que igualmente tenemos que aplicar una transformacion a esos datos para pasarlos a campos numéricos.\n",
    "Se resuelve utilizar la media de valores de un atributo para llenar los lugares en donde hay falta de información (Campos NaN), esto es porque el algoritmo k-means precisa todos los datos completos y numéricos.\n",
    "\n",
    "Adicionalmente se probaron varias opciones de extraccion de atributos, que se explica con más detalle en la sección de experimentación.\n",
    "\n",
    "\n",
    "### 2.2 Algoritmo\n",
    "En este laboratorio se utilizaron dos algoritmos, PCA y k-means. Para el primero se utilizó la implementación de scikit. Dado que la dimensión de los datos es muy grande (16 atributos) se utiliza PCA para la visualización de los mismos en dos dimesiones.\n",
    "\n",
    "Por otro lado k-means fue implementado según lo visto en el teórico, a partir de los siguientes pasos:\n",
    "1. Dado el dataset y un entero k, elegimos k instancias de forma aleatoria para luego utilizarlos como los centroides iniciales.\n",
    "2. Luego para cada instancia del dataset calculamos a cuál centroide es más cercano, según la norma euclidana, y lo agregamos a ese cluster. Más adelante veremos que probamos utilizar la similitud coseno.\n",
    "3. Una vez que cada instancia del dataset ya fue asignada a un cluster, calculamos los nuevos centroides. Para ello, para cada cluster, realizamos la suma coordenada a coordenada de las instancias y dividimos entre el número de instancias de ese cluster.\n",
    "4. Con los nuevos centroides y los anteriores, comparamos cuanto se movieron, si no se movieron \"mucho\" de la posición anterior entonces el algoritmo terminó, y retornamos los clusters con su respectivo centroide. En caso contrario repetimos el algoritmo a partir del paso 2.\n",
    "\n",
    "El criterio que utilizamos para decidir que un centroide no se movió \"mucho\" es que la distancia entre el nuevo ceintroide y el anterior varíe menos de `0.01`. Para esta distancia utilizamos la misma que en el paso 2.\n",
    "\n",
    "\n",
    "### 2.3 Evaluación\n",
    "\n",
    "Utilizamos el método del codo para evaluar cuál es el número óptimo de clusters. Para ello realizamos la implementación de la inercia obtenida tras aplicar el K-means.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probó con dos configuraciones de atributos distintas:\n",
    "\n",
    "- Todos los atributos menos ['Country', 'Region', 'Agriculture','Industry','Service\", 'Climate']\n",
    "\n",
    "- Los atributos [\"Net migration\",\"Infant mortality (per 1000 births)\", \"GDP ($ per capita)\", \"Literacy (%)\",\"Phones (per 1000)\",\"Arable (%)\",\"Crops (%)\",\"Agriculture\",\"Industry\",\"Service\"]\n",
    "\n",
    "Primero se muestra en una gráfica la dispocisión de los países luego de haber aplicado PCA, de esta forma podemos ver cada país en que parte de la gráfica 2D se encuentra. Luego se corre el algoritmo Elbow en donde podemos ver dónde se genera el \"codo\" para saber cuantos clusters aplicar k-means. Se corre k-means generando los clusters con el k definido a partir de Elbow y se muestran los clusters en una gráfica utilizando PCA. Por último se imprime en consola para cada cluster la cantidad de países de cada región que caen en el cluster.\n",
    "\n",
    "A partir de estas pruebas se generaron las siguientes imágenes:\n",
    "\n",
    "- Primer experimento: Todos los atributos menos ['Country', 'Region', 'Agriculture','Industry','Service\", 'Climate']\n",
    "\n",
    "![primer experimento sin clasificar](img/sin_clasificar_elbowN6.png)\n",
    "\n",
    "_Distribución de los datos segun el primer experimento_\n",
    "\n",
    "![](img/elbowN6.png)\n",
    "\n",
    "_Elbow para el primer experimento_\n",
    "\n",
    "![](img/clasificar_elbowN6.png)\n",
    "\n",
    "_Primer experimento con k=6_\n",
    "\n",
    "- Segundo experimento: Los atributos [\"Net migration\",\"Infant mortality (per 1000 births)\", \"GDP ($ per capita)\", \"Literacy (%)\",\"Phones (per 1000)\",\"Arable (%)\",\"Crops (%)\",\"Agriculture\",\"Industry\",\"Service\"]\n",
    "\n",
    "![Segundo experimento sin clasificar](img/sin_clasificar_elbowN3.png)\n",
    "\n",
    "_Distribución de los datos segun el segundo experimento_\n",
    "\n",
    "![](img/elbowN3.png)\n",
    "\n",
    "_Elbow para el segundo experimento_\n",
    "\n",
    "![](img/clasificar_elbowN3.png)\n",
    "\n",
    "_Segundo experimento con k=3_\n",
    "\n",
    "\n",
    "Para ambos casos se corrió el algoritmo de Elbow, en donde para el primer conjunto de atributos no es tan claro, pero tomamos el codo como 6 mientras que para el segundo se ve claramente el codo en el valor 3. Para evaluar que tan efectivo es el metodo Elbow probamos en el segundo experimento, donde es más notorio el codo (k = 3), poner k = 4 y obtuvimos el siguiente resultado:\n",
    "\n",
    "![](img/NDeberiaSer3PeroEs4.png)\n",
    "\n",
    "_Experimento 2 pero con k=4 cuando deberia ser 3_\n",
    "\n",
    "Como se puede observar los puntos empiezan a mezclarse y por ende vemos que el uso de Elbow es importante para generar las zonas bien definidas.\n",
    "\n",
    "Es importante notar que Kmeans se corre con las n dimensiones y no luego de aplicado PCA. Realizamos esta aclaración porque al visualizar los datos en 2D se pueden ver puntos que estan mas cerca de otros centroides que del centroide al que pertencen. De esta manera se utiliza PCA solo para la visualización y no se pierden datos para el algoritmo.\n",
    "\n",
    "\n",
    "Para este segundo experimento se usaron los datos de cuantos paises por región hay en cada cluster para realizar gráficas y observar si los clusters tienen alguna relación con las regiones. \n",
    "\n",
    "![](img/RegionesPorCluster.png)\n",
    "\n",
    "\n",
    "Observando la gráfica se decide agrupar las regiones según el cluster que tiene más cantidad de países de esa región, 'WESTERN EUROPE', 'NORTHERN AMERICA', 'BALTICS' y 'EASTERN EUROPE' en grupo 0, que tienen mayor cantidad de países del cluster 0, las regiones 'LATIN AMER. & CARIB', 'OCEANIA', 'NEAR EAST', 'C.W. OF IND. STATES', 'NORTHERN AFRICA' y 'ASIA (EX. NEAR EAST) se agruparon en grupo 2 y tienen mayor cantidad de países del cluster 2 y 'SUB-SAHARAN AFRICA' forma el grupo 1.\n",
    "\n",
    "Con esas agrupaciones se hizo una gráfica en función de la cantidad de países de cada cluster en cada grupo.\n",
    "\n",
    "\n",
    "![](img/GruposPorCluster.png)\n",
    "\n",
    "Se puede ver como un 90% de los países del grupo 0 cayeron en el cluster 0, un 70% de los países del grupo 2 cayeron en el cluster 2 y un 65% del grupo 1 quedaron en el cluster 1.\n",
    "\n",
    "También se decide comparar los atributos de los distintos centroides ya que estos tienen la media de todos los países del cluster y se grafica una comparación de algunos de los atributos:\n",
    "\n",
    "![](img/AtributosPorCentroide.png)\n",
    "\n",
    "Primero se observa que el centroide 1 tiene muchísima más 'Infant mortality' que los otros centroides, mientras que el centroide 0 prácticamente no tiene en comparación. \n",
    "\n",
    "Por otro lado el centroide 0 tienen muchísimo más 'GDP', 'Phones' y 'Literacy'; el centroide 1 casi nada y el centroide 2 intemedio. \n",
    "\n",
    "Por último se puede ver en los atributos 'Agriculture', 'Industry' y 'Service' que el centroide 0 tiene poco 'Agriculture', intermedio 'Industry' y mucho 'Sevice'; el centroide 1 lo contrario y el centroide 2 intermedio en 'Agriculture' y 'Sevirce' y más en 'Industry'.\n",
    "\n",
    "Parecería ser que el cluster 0 se corresponde a los países de alto nivel económico, los del cluster 2 de nivel medio y los del cluster 1 los restantes con un nivel más bajo.\n",
    "\n",
    "En cuanto a Uruguay vemos que queda en el cluster 2, que se correspondería a los países de nivel medio, junto con muchos países de Latinoamérica como Brazil, Colombia, Ecuador, Argentina, y más. Además se observa que está más cerca del cluster 0 que del 1.`\n",
    "\n",
    "Probamos utilizar distancia euclideana y similitud coseno, sin embargo esta ultima al ejecutar k-means y visualizar usando PCA no separó claramente los clusters por lo cual decidimos no utilizarla.\n",
    "\n",
    "![](img/simCoseno.png)\n",
    "_K-means con similitud coseno k=3_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión\n",
    "Concluimos que es importante realizar un preprocesamiento de los datos correcto para lograr una buena separacion de los clusters, eso nos damos cuenta con la selección mas acotada de atributos del segundo experimento. Para este último notamos una separación en tres cluster en donde se encuentran los paises con mayor nivel económico (azules), los nivel económico medio (verdes) y los de nivel bajo (rojos).\n",
    "\n",
    "Notamos como es importante el uso de algun método para la seleccion de la cantidad de clusters (el hiperparámetro 'k'), en nuestro caso el metodo Elbow ya que esto permite un balance entre la dispersión y la especificación del modelo.\n",
    "\n",
    "También creemos importante destacar el uso de la distancia Euclidiana debido a que la distancia (o mejor dicho, similitud) coseno es aplicable en casos en donde no importa la magnitud del vector, como en por ejemplo casos donde se busca generalizar textos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anexo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Código principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parte_ayb import main\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Código con similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parte_ayb import coseno\n",
    "coseno()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a12ff8c7a91ea37f5992d09ea518b599018c1dcd85b39a87bb2da8ef6d0f94da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
