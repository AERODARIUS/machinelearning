{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Entrega 2 - Arboles de decisión\n",
    "\n",
    "### Grupo 6:\n",
    "     - Darío Cruz  4768599-2\n",
    "     - Agustin Tornaría 5047825-5\n",
    "     - Renzo Beux 5076905-8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Objetivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "El objetivo de esta tarea es implementar el algoritmo ID3 para utilizarlo con el conjunto de datos de Heart Disease UCI.\n",
    "\n",
    "Se compararan los resultados obtenidos con los de la implementación de Decision Tree de scikit-learn."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Diseño"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Preprocesamiento de datos\r\n",
    "<!-- - Decisiones sobre tratamiento de datos numéricos, faltantes, etc. antes de la aplicación de el algoritmo\r\n",
    "- Selección/generación de atributos -->\r\n",
    "\r\n",
    "Los datos son presentado en una planilla separada por comas (CSV) la cual es consumida utilizando Pandas. No se realiza ningun filtrado ni corrección sobre los datos. Simplemente se parte los datos en dos conjuntos, uno para relizar el entrenamiento y otro para realizar las pruebas.\r\n",
    "La selección de atributos esta dada por el algoritmo mismo la cual será explicada a continuación.\r\n",
    "\r\n",
    "\r\n",
    "## 2.2 Algoritmo\r\n",
    "<!-- Extensiones del algoritmo original necesarias para la resolución del problema: tratamiento de atributos faltantes, numéricos, etc. (si es el propio algoritmo el que lo maneja), implementaciones adicionales necesarias para manejar ensambles de clasificadores, etc. -->\r\n",
    "\r\n",
    "Se utilizó el algoritmo ID3 para la generacion del arbol. Se programó el algoritmo visto en clase y presentado en el libro del curso. Para cada atributo se calcula la ganancia de todas las particiones en dos. Para ello se ordenan y agrupan los valores de la columna correspondiente al atributo elegido, calculando para cada partición la ganancia de la misma. Esta ganancia es calculada a apartir de la entropía de ambas partes de la particion.\r\n",
    "\r\n",
    "Teniendo entonces todas las ganancias de todos los atributos para todas la particiones, nos quedamos con el atributo y la partición que tengan la mayor ganancia. \r\n",
    "\r\n",
    "Habiendo obtenido esto quitamos la columna con la propiedad anteriormente elegida del dataset y se la pasamos a los siguientes nodos del arbol, guardando en el nodo actual el atributo y el treshhold por el cual se particiona en dos. De esta manera el arbol de decisión se va armando recursivamente.\r\n",
    "\r\n",
    "\r\n",
    "## 2.3 Evaluación\r\n",
    "<!-- - Qué conjunto de métricas se utilizan para la evaluación de la solución y su definición\r\n",
    "- Sobre qué conjunto(s) se realiza el entrenamiento, ajuste de la solución, evaluación, etc. Explicar cómo se construyen estos conjuntos. -->\r\n",
    "\r\n",
    "Para la evaluacion de nuestro algoritmo se utiliza la libreria scikit-learn de Python. Utilizando la utilidad \"tree\" junto con la implementacion \"DecisionTreeClassifier(criterion=\"entropy\")\", en donde es importante notar que se setea el criterio como \"entropy\" ya que por defecto SciKit selecciona Gini como criterio.\r\n",
    "\r\n",
    "Se entrena en con un porcentaje de los datos y se utilizan el resto de los datos para probar el arbol de decisión. Se compararon con los porcentajes obtenidos con SciKit.\r\n",
    "\r\n",
    "En un principio se entrenó con 80% de los datos, luego se experimientó con más porcentajes.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Experimentación"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los experimentos que se realizaron se basan en elegir un porcentaje de los datos para entrenar el algoritmo y el restante de los datos para probar las predicciones. Los porcentajes con los que probamos fueron los siguientes:\r\n",
    "\r\n",
    "| Entrenamiento | Test | Presición |\r\n",
    "|---------------|------|-----------|\r\n",
    "| 9%            | 91%  | 59.0%     |\r\n",
    "| 19%           | 81%  | 72.7%     |\r\n",
    "| 29%           | 71%  | 70.8%     |\r\n",
    "| 39%           | 61%  | 75.6%     |\r\n",
    "| 49%           | 51%  | 77.4%     |\r\n",
    "| 59%           | 41%  | 76.8%     |\r\n",
    "| 69%           | 31%  | 73.4%     |\r\n",
    "| 79%           | 21%  | 81.2%     |\r\n",
    "| 89%           | 11%  | 76.4%     |\r\n",
    "| 99%           |  1%  | 75.0%     |\r\n",
    "\r\n",
    "Luego de ver este comportamiento en el algoritmo, decidimos probar una variedad más grande de datos, empezando en 9% y terminando en 99%, aumentando de a 10%. Luego graficamos los resultados.\r\n",
    "\r\n",
    "![Aciertos por experimento - algoritmo](grafica_nuestroID3.png)\r\n",
    "\r\n",
    "_En la gráfica se puede ver el porcentaje de aciertos a medida que se aumenta el porcentaje de entrenamiento_\r\n",
    "\r\n",
    "# Repetimos lo mismo con el algoritmo de scikit-learn\r\n",
    "\r\n",
    "| Entrenamiento | Test | Presición |\r\n",
    "|---------------|------|-----------|\r\n",
    "| 9%            | 91%  | 53.6%     |\r\n",
    "| 19%           | 81%  | 75.6%     |\r\n",
    "| 29%           | 71%  | 73.6%     |\r\n",
    "| 39%           | 61%  | 72.4%     |\r\n",
    "| 49%           | 51%  | 76.7%     |\r\n",
    "| 59%           | 41%  | 79.2%     |\r\n",
    "| 69%           | 31%  | 74.4%     |\r\n",
    "| 79%           | 21%  | 75.0%     |\r\n",
    "| 89%           | 11%  | 82.3%     |\r\n",
    "| 99%           |  1%  | 75.0%     |\r\n",
    "\r\n",
    "![Aciertos por experimento - scikit-learn](grafica_scikit.png)\r\n",
    "\r\n",
    "\r\n",
    "Se puede ver en ambas graficas, como al aumentar los datos de entrenamiento aumenta el porcentaje de aciertos, sin embargo en determinado punto (pasando el 79% en nuestro algoritmo y el 89% en el de SciKit) el porcentaje de aciertos comienza a decaer\r\n",
    "\r\n",
    "Algo que notamos que nos parece importante al momento de comparar algoritmos es que nuestro algoritmo es relativamente mas lento que Scikit-Learn. Sin embargo creemos que esto se da por varios motivos pero el que suponemos más probable es por el uso de estructuras optimizadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Conclusión"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se puede observar que al empezar a utilizar más datos de entrenamiento mejoran los resultados, pero si se aumentan mucho el arbol se vuelve demasiado específico y esto hace que empeoren los resultados. Por esto el mejor resultado se da en un entorno cercano a 80% donde se tienen suficientes datos para obtener un buen resultado pero no tantos como para empeorarlo.\r\n",
    "Una forma de mejorar el problema de hacerlo demasiado específico es utilizar la técnica de poda. Donde se convierten algunas ramas en hojas.\r\n",
    "Otro punto de mejora puede ser utilizar el indice de Gini en lugar de la entropía.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}