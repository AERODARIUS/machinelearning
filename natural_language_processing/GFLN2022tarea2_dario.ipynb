{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Parte 1**\n",
        "\n",
        "En esta parte se implementarán gramáticas con rasgos, Feature Grammars: https://www.nltk.org/howto/featgram.html, utilizando las estructuras de rasgos que provee la librería NLTK: https://www.nltk.org/howto/featstruct.html.\n",
        "\n",
        "Se partirá de un ejemplo simple, inspirado en los links antes mencionados, que se expandirá para resolver lo que se pide en la letra de la tarea.\n"
      ],
      "metadata": {
        "id": "d8k0Zfsqt0xH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxxp_04upx29"
      },
      "outputs": [],
      "source": [
        "from nltk.grammar import FeatStructNonterminal, FeatureGrammar\n",
        "from nltk import grammar, parse\n",
        "\n",
        "grammar = '''\n",
        "\n",
        "% start S\n",
        "\n",
        "#####################\n",
        "# Grammar Rules\n",
        "\n",
        "S -> NP[NUM=?n, PER=?p] VP[NUM=?n, PER=?p]\n",
        "NP[GEN=?g, NUM=?n, PER=?p] -> D[GEN=?g, NUM=?n] N[GEN=?g, NUM=?n, PER=?p]\n",
        "VP[NUM=?n, PER=?p] -> V[NUM=?n, PER=?p]\n",
        "\n",
        "\n",
        "# ###################\n",
        "# Lexical Rules\n",
        "\n",
        "D[GEN=m, NUM=sg]  -> 'el'\n",
        "D[GEN=m, NUM=pl]  -> 'los'\n",
        "D[GEN=f, NUM=sg]  -> 'la'\n",
        "D[GEN=f, NUM=pl]  -> 'las'\n",
        "\n",
        "N[GEN=m, NUM=sg, PER=ter] -> 'perro'\n",
        "N[GEN=m, NUM=pl, PER=ter] -> 'perros'\n",
        "N[GEN=f, NUM=sg, PER=ter] -> 'perra'\n",
        "N[GEN=f, NUM=pl, PER=ter] -> 'perras'\n",
        "\n",
        "V[NUM=sg, PER=ter] -> 'ladra'\n",
        "V[NUM=pl, PER=ter] -> 'ladran'\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "gram = FeatureGrammar.fromstring(grammar)\n",
        "\n",
        "parser = parse.FeatureEarleyChartParser(gram)\n",
        "\n",
        "trees = list(parser.parse(['el', 'perro', 'ladra']))\n",
        "\n",
        "for tree in trees:\n",
        "    print(tree)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escriba su gramática aquí\n"
      ],
      "metadata": {
        "id": "MkaMUJWZuZOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parte 2**\n",
        "\n",
        "En esta parte se trabajará con el parser de dependencias de Spacy para el español. Se usará un modelo para el español entrenado utilizando BERT.\n",
        "\n",
        "Referencias:\n",
        "\n",
        "https://spacy.io/\n",
        "\n",
        "https://spacy.io/models/es\n",
        "\n",
        "https://colab.research.google.com/github/DerwenAI/spaCy_tuTorial/blob/master/spaCy_tuTorial.ipynb#scrollTo=5f6yzdylViJ6\n",
        "\n",
        "Nota: se recomienda habilitar el uso de GPU (Runtime -> Change runtime type)\n"
      ],
      "metadata": {
        "id": "bEcKlPxRucrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://huggingface.co/spacy/es_dep_news_trf/resolve/main/es_dep_news_trf-any-py3-none-any.whl\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"es_dep_news_trf\")\n"
      ],
      "metadata": {
        "id": "CINha3NBvNe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ej = nlp(\"El perro ladra.\")\n",
        "\n",
        "for token in ej:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.head)\n",
        "\n",
        "displacy.render(ej, style=\"dep\", jupyter=True)\n"
      ],
      "metadata": {
        "id": "P0nIDPmWyQx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realice el parsing de los ejemplos de la letra aquí\n"
      ],
      "metadata": {
        "id": "9d7D6rvZ0rPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parte 3**\n",
        "\n",
        "Ejemplo de uso de transformers para question answering\n",
        "En este ejemplo se usa un modelo entrenado para la tarea QA, disponible en el sitio https://huggingface.co/ (https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es).\n",
        "\n",
        "El modelo se basa en un modelo de lenguaje de la familia BERT (https://www.aclweb.org/anthology/N19-1423/), sobre el cual se hizo fine tuning usando el corpus SQuAD-es (https://www.aclweb.org/anthology/2020.lrec-1.677/), una adaptación al español del corpus SQuAD (https://rajpurkar.github.io/SQuAD-explorer/).\n",
        "\n",
        "El modelo para QA recibe un texto y una pregunta, y devuelve un substring del texto candidato a ser una respuesta a la pregunta. También devuelve un score que indica qué tan confiable es el resultado."
      ],
      "metadata": {
        "id": "2z7dOIEM0xfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\n",
        "    'question-answering',\n",
        "    model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
        "    tokenizer=(\n",
        "        'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
        "        {\"use_fast\": False}\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "HLpyk4J21tTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respuesta = [qa_pipeline({'question': '¿Quién informó sobre los pacientes con neumonía?', 'context': 'La primera aparición pública ocurre el 31 de ese mes, cuando la Organización Mundial de la Salud (OMS) fue informada por funcionarios de salud chinos sobre un grupo de 41 pacientes con una misteriosa neumonía.'})]\n",
        "print(respuesta)\n"
      ],
      "metadata": {
        "id": "9YGVyiKO2Pgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analice los ejemplos de la letra aquí\n"
      ],
      "metadata": {
        "id": "9p602nRX3elT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parte opcional aquí\n"
      ],
      "metadata": {
        "id": "4Z-O9tRa3h2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}